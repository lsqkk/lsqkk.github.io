#!/usr/bin/env python3
"""
ä¸€é”®ç”Ÿæˆsitemap.xmlè„šæœ¬
æ³¨æ„ç”Ÿæˆåæ›¿æ¢å·¦å³æ–œæ 
"""

import os
import xml.etree.ElementTree as ET
from xml.dom import minidom
from datetime import datetime
from pathlib import Path
import webbrowser

def generate_sitemap():
    """
    ä¸€é”®ç”Ÿæˆsitemap.xml
    è‡ªåŠ¨æ£€æµ‹å½“å‰ç›®å½•ä½œä¸ºç½‘ç«™æ ¹ç›®å½•
    """
    
    # è‡ªåŠ¨è·å–å½“å‰ç›®å½•ä½œä¸ºç½‘ç«™æ ¹ç›®å½•
    root_dir = "D:\git\lsqkk\lsqkk.github.io"
    base_url = "https://lsqkk.github.io/"
    
    # é»˜è®¤æ’é™¤çš„ç›®å½•
    exclude_dirs = [
        '.git', '.vscode', '__pycache__', 'node_modules',
        '.idea', '.venv','venv', 'env', '.github', 'dist', 'build',
        'cache', '.svn', '.hg', 'test', 'tests', 'temp', 'rubbish', 'template'
    ]
    
    # é»˜è®¤æ’é™¤çš„æ–‡ä»¶
    exclude_files = [
        'sitemap.xml', 'robots.txt', '.gitignore', 'CNAME',
        'README.md', 'LICENSE', 'readme.md',  '404.html', 'auth.html'
    ]
    
    # åˆ›å»ºXMLæ ¹å…ƒç´ 
    urlset = ET.Element('urlset')
    urlset.set('xmlns', 'http://www.sitemaps.org/schemas/sitemap/0.9')
    
    # æ‰«ææ‰€æœ‰HTMLæ–‡ä»¶
    html_files = []
    
    for root, dirs, files in os.walk(root_dir):
        # æ’é™¤ä¸éœ€è¦çš„ç›®å½•
        dirs[:] = [d for d in dirs if d not in exclude_dirs]
        
        for file in files:
            if file.endswith('.html') or file.endswith('.htm'):
                # æ’é™¤ä¸éœ€è¦çš„æ–‡ä»¶
                if file in exclude_files:
                    continue
                
                file_path = os.path.join(root, file)
                html_files.append(file_path)
    
    print(f"âœ… æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶")
    print("-" * 40)
    
    if len(html_files) == 0:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•HTMLæ–‡ä»¶ï¼")
        print("è¯·ç¡®ä¿è„šæœ¬æ”¾åœ¨ç½‘ç«™æ ¹ç›®å½•ä¸‹ï¼Œä¸”ç½‘ç«™åŒ…å«HTMLæ–‡ä»¶")
        return
    
    # ä¸ºæ¯ä¸ªHTMLæ–‡ä»¶åˆ›å»ºURLæ¡ç›®
    url_count = 0
    
    for file_path in html_files:
        # è·å–ç›¸å¯¹è·¯å¾„
        rel_path = os.path.relpath(file_path, root_dir)
        
        # è®¡ç®—æ–‡ä»¶å¤¹æ·±åº¦ï¼ˆç”¨äºç¡®å®šä¼˜å…ˆçº§ï¼‰
        depth = rel_path.count(os.sep)
        
        # ä¼˜å…ˆçº§çš„è®¡ç®—ï¼šæ ¹ç›®å½•ä¸º1.0ï¼Œæ¯æ·±ä¸€çº§å‡å°‘0.1ï¼Œæœ€ä½0.1
        priority = max(1.0 - (depth * 0.1), 0.1)
        
        # å¯¹äºindex.htmlæ–‡ä»¶ï¼Œæ·±åº¦å‡1ï¼ˆå› ä¸ºindex.htmlé€šå¸¸ä»£è¡¨å½“å‰ç›®å½•ï¼‰
        file_name = os.path.basename(rel_path)
        if file_name == 'index.html' or file_name == 'index.htm':
            depth = max(0, depth - 1)
            priority = max(1.0 - (depth * 0.1), 0.1)
        
        # æ„å»ºå®Œæ•´URL
        # å¦‚æœæ˜¯index.htmlï¼Œä½¿ç”¨ç›®å½•è·¯å¾„
        if file_name == 'index.html' or file_name == 'index.htm':
            dir_path = os.path.dirname(rel_path)
            if dir_path == '.':
                url_path = '/'
            else:
                url_path = f'/{dir_path}/'
        else:
            # ç§»é™¤.htmlæˆ–.htmåç¼€ï¼Œåˆ›å»ºæ›´å‹å¥½çš„URL
            base_name = rel_path[:-5] if rel_path.endswith('.html') else rel_path[:-4]
            url_path = f'/{base_name}/'
        
        full_url = base_url.rstrip('/') + url_path
        
        # è·å–æ–‡ä»¶æœ€åä¿®æ”¹æ—¶é—´
        try:
            lastmod = datetime.fromtimestamp(os.path.getmtime(file_path)).strftime('%Y-%m-%d')
        except:
            lastmod = datetime.now().strftime('%Y-%m-%d')
        
        # åˆ›å»ºURLå…ƒç´ 
        url_elem = ET.SubElement(urlset, 'url')
        
        # æ·»åŠ å­å…ƒç´ 
        loc = ET.SubElement(url_elem, 'loc')
        loc.text = full_url
        
        lastmod_elem = ET.SubElement(url_elem, 'lastmod')
        lastmod_elem.text = lastmod
        
        changefreq = ET.SubElement(url_elem, 'changefreq')
        changefreq.text = 'monthly'  # é»˜è®¤æ›´æ–°é¢‘ç‡
        
        priority_elem = ET.SubElement(url_elem, 'priority')
        priority_elem.text = f"{priority:.1f}"
        
        url_count += 1
        
        # æ˜¾ç¤ºè¿›åº¦
        if url_count <= 3:  # åªæ˜¾ç¤ºå‰3ä¸ªURL
            print(f"  {url_count:3d}. {full_url} (ä¼˜å…ˆçº§: {priority:.1f})")
        elif url_count == 4:
            print(f"  ... è¿˜æœ‰ {len(html_files) - 10} ä¸ªURLæœªæ˜¾ç¤º")
    
    # ç”ŸæˆXMLå­—ç¬¦ä¸²
    xml_string = ET.tostring(urlset, encoding='utf-8')
    
    # ç¾åŒ–XMLè¾“å‡º
    reparsed = minidom.parseString(xml_string)
    pretty_xml = reparsed.toprettyxml(indent='  ', encoding='utf-8')
    
    # å†™å…¥æ–‡ä»¶
    output_path = os.path.join(root_dir, 'sitemap.xml')
    with open(output_path, 'wb') as f:
        f.write(pretty_xml)
    
    print("-" * 30)
    print(f"sitemap.xml ç”ŸæˆæˆåŠŸï¼Œä½äº {output_path} ï¼ŒåŒ…å« {url_count} ä¸ªURL")
    
    # è¿”å›è¾“å‡ºè·¯å¾„ä¾›åç»­å¤„ç†ä½¿ç”¨
    return output_path


def post_generation_replace(file_path):
    """
    ç”Ÿæˆåæ›¿æ¢åŠŸèƒ½ï¼š
    1. å°†æ‰€æœ‰å³æ–œæ "\"æ›¿æ¢æˆå·¦æ–œæ "/"
    2. å°†"io//"æ›¿æ¢ä¸º"io/"
    
    Args:
        file_path: è¦å¤„ç†çš„æ–‡ä»¶è·¯å¾„
    """
    print("\n" + "=" * 60)
    print("å¼€å§‹æ‰§è¡Œç”Ÿæˆåæ›¿æ¢åŠŸèƒ½...")
    
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ç»Ÿè®¡åŸå§‹å†…å®¹ä¸­çš„æ–œæ æ•°é‡
        original_backslashes = content.count('\\')
        original_double_slashes = content.count('io//')
        
        print(f"åŸå§‹å†…å®¹ç»Ÿè®¡:")
        print(f"  - å³æ–œæ (\\)æ•°é‡: {original_backslashes}")
        print(f"  - 'io//'å‡ºç°æ¬¡æ•°: {original_double_slashes}")
        
        # æ‰§è¡Œæ›¿æ¢
        # 1. å°†æ‰€æœ‰å³æ–œæ æ›¿æ¢ä¸ºå·¦æ–œæ 
        content = content.replace('\\', '/')
        
        # 2. å°†"io//"æ›¿æ¢ä¸º"io/"
        content = content.replace('io//', 'io/')
        
        # ç»Ÿè®¡æ›¿æ¢åçš„æ–œæ æ•°é‡
        new_backslashes = content.count('\\')
        new_double_slashes = content.count('io//')
        
        print(f"\næ›¿æ¢åå†…å®¹ç»Ÿè®¡:")
        print(f"  - å³æ–œæ (\\)æ•°é‡: {new_backslashes}")
        print(f"  - 'io//'å‡ºç°æ¬¡æ•°: {new_double_slashes}")
        
        # è®¡ç®—æ›¿æ¢æ•°é‡
        replaced_backslashes = original_backslashes - new_backslashes
        replaced_double_slashes = original_double_slashes - new_double_slashes
        
        # ä¿å­˜æ›¿æ¢åçš„å†…å®¹
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"\nâœ… æ›¿æ¢å®Œæˆ:")
        print(f"  - æ›¿æ¢å³æ–œæ æ•°é‡: {replaced_backslashes}")
        print(f"  - æ›¿æ¢'io//'æ•°é‡: {replaced_double_slashes}")
        print(f"  - æ–‡ä»¶å·²æ›´æ–°: {file_path}")
        
        # æ˜¾ç¤ºæ›¿æ¢ç¤ºä¾‹ï¼ˆå¦‚æœæœ‰æ›¿æ¢çš„è¯ï¼‰
        if replaced_backslashes > 0 or replaced_double_slashes > 0:
            print(f"\nğŸ“ æ›¿æ¢ç¤ºä¾‹:")
            
            # æŸ¥æ‰¾æ›¿æ¢åçš„ç¤ºä¾‹
            lines = content.split('\n')
            for i, line in enumerate(lines[:5]):  # æ˜¾ç¤ºå‰5è¡Œä¸­çš„ç¤ºä¾‹
                if 'io/' in line and 'loc' in line:
                    print(f"  ç¬¬{i+1}è¡Œ: {line.strip()[:80]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ›¿æ¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return False


def main():
    """ä¸»å‡½æ•° - ç›´æ¥è¿è¡Œ"""
    try:
        # ç”Ÿæˆsitemap
        output_path = generate_sitemap()
        
        if output_path and os.path.exists(output_path):
            # æ‰§è¡Œç”Ÿæˆåæ›¿æ¢
            success = post_generation_replace(output_path)
            
            if success:
                print("\n" + "=" * 60)
                print("ğŸ‰ æ‰€æœ‰æ“ä½œå·²å®Œæˆï¼")
            else:
                print("\nâš ï¸  ç”Ÿæˆå®Œæˆï¼Œä½†æ›¿æ¢åŠŸèƒ½æ‰§è¡Œå¤±è´¥")
        else:
            print("\nâš ï¸  ç”Ÿæˆå¤±è´¥æˆ–è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")

    except Exception as e:
        print(f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    
    # ç­‰å¾…ç”¨æˆ·æŒ‰ä»»æ„é”®é€€å‡º
    input("\næŒ‰å›è½¦é”®é€€å‡º...")

if __name__ == '__main__':
    main()